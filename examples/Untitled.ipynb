{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099c833-4776-4a44-adb4-61569794453f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c9bc264-e898-4eb3-90bd-ce4957bc73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result: {\n",
      "  \"message\": \"s_learner model trained successfully\",\n",
      "  \"model_path\": \"s_learner_20250302_072129.pkl\",\n",
      "  \"model_info\": {\n",
      "    \"model_type\": \"s_learner\",\n",
      "    \"features\": [\n",
      "      \"Recency\",\n",
      "      \"History\",\n",
      "      \"Mens\",\n",
      "      \"Womens\",\n",
      "      \"Newbie\"\n",
      "    ],\n",
      "    \"metrics\": {\n",
      "      \"actual_ate\": 0.5,\n",
      "      \"estimated_ate\": 0.11333333333333333,\n",
      "      \"control_outcome\": 0.5,\n",
      "      \"treatment_outcome\": 1.0\n",
      "    },\n",
      "    \"timestamp\": \"20250302_072129\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Uplift Modeling APIを利用するためのサンプルNotebook\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# 1. モデルのトレーニング\n",
    "train_payload = {\n",
    "    \"data\": [\n",
    "        {\"Recency\": 10, \"History\": 100, \"Mens\": 1, \"Womens\": 0, \"Newbie\": 0, \"treatment\": 1, \"Conversion\": 1},\n",
    "        {\"Recency\": 12, \"History\": 120, \"Mens\": 1, \"Womens\": 0, \"Newbie\": 0, \"treatment\": 1, \"Conversion\": 0},\n",
    "        {\"Recency\": 8, \"History\": 90, \"Mens\": 1, \"Womens\": 0, \"Newbie\": 0, \"treatment\": 0, \"Conversion\": 0},\n",
    "        {\"Recency\": 15, \"History\": 80, \"Mens\": 1, \"Womens\": 0, \"Newbie\": 0, \"treatment\": 0, \"Conversion\": 1},\n",
    "        {\"Recency\": 5, \"History\": 200, \"Mens\": 0, \"Womens\": 1, \"Newbie\": 0, \"treatment\": 0, \"Conversion\": 0},\n",
    "        {\"Recency\": 7, \"History\": 180, \"Mens\": 0, \"Womens\": 1, \"Newbie\": 0, \"treatment\": 0, \"Conversion\": 1},\n",
    "        {\"Recency\": 3, \"History\": 210, \"Mens\": 0, \"Womens\": 1, \"Newbie\": 0, \"treatment\": 1, \"Conversion\": 0},\n",
    "        {\"Recency\": 4, \"History\": 220, \"Mens\": 0, \"Womens\": 1, \"Newbie\": 0, \"treatment\": 1, \"Conversion\": 1},\n",
    "        {\"Recency\": 20, \"History\": 50, \"Mens\": 0, \"Womens\": 0, \"Newbie\": 1, \"treatment\": 0, \"Conversion\": 0},\n",
    "        {\"Recency\": 25, \"History\": 30, \"Mens\": 0, \"Womens\": 0, \"Newbie\": 1, \"treatment\": 1, \"Conversion\": 1}\n",
    "    ],\n",
    "    \"features\": [\"Recency\", \"History\", \"Mens\", \"Womens\", \"Newbie\"],\n",
    "    \"treatment_col\": \"treatment\",\n",
    "    \"outcome_col\": \"Conversion\",\n",
    "    \"model_type\": \"s_learner\",\n",
    "    \"model_params\": {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{API_URL}/train\", json=train_payload)\n",
    "train_result = response.json()\n",
    "print(\"Train Result:\", json.dumps(train_result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fc46c73-73b5-4973-a1ce-7ada47e90f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s_learner_20250302_072129.pkl'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4683fab7-4665-4999-aa7b-82e95ee1f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Result: {\n",
      "  \"detail\": \"Error during prediction: float() argument must be a string or a number, not 'list'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# トレーニング済みモデルのパスを取得\n",
    "model_path = train_result[\"model_path\"]\n",
    "\n",
    "# 2. 予測の実行\n",
    "predict_payload = {\n",
    "    \"features\": [\n",
    "        {\"Recency\": 8, \"History\": 150, \"Mens\": 1, \"Womens\": 0, \"Newbie\": 1},\n",
    "        {\"Recency\": 3, \"History\": 250, \"Mens\": 0, \"Womens\": 1, \"Newbie\": 0}\n",
    "    ],\n",
    "    \"model_path\": model_path\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{API_URL}/predict\", json=predict_payload)\n",
    "predict_result = response.json()\n",
    "print(\"Predict Result:\", json.dumps(predict_result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c52039-dc18-47d6-8bfc-901244b71ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4c136-4f9d-498e-8cc7-89a323345916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b94c6e8-f146-4cba-9dc0-cde9b46c4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ件数: 64000\n",
      "訓練データ: 44800件, テストデータ: 19200件\n",
      "\n",
      "トレーニング: s_learner\n",
      "  成功: s_learner\n",
      "  実測ATE: 0.00568\n",
      "  推定ATE: 0.00340\n",
      "\n",
      "トレーニング: t_learner\n",
      "  成功: t_learner\n",
      "  実測ATE: 0.00568\n",
      "  推定ATE: 0.00484\n",
      "\n",
      "トレーニング: x_learner\n",
      "  成功: x_learner\n",
      "  実測ATE: 0.00568\n",
      "  推定ATE: 0.00488\n",
      "\n",
      "トレーニング: r_learner\n",
      "  成功: r_learner\n",
      "  実測ATE: 0.00568\n",
      "  推定ATE: 0.00511\n",
      "\n",
      "トレーニング: causal_tree\n",
      "  成功: causal_tree\n",
      "  実測ATE: 0.00568\n",
      "  推定ATE: 0.00809\n",
      "\n",
      "トレーニング: uplift_rf\n",
      "  成功: uplift_rf\n",
      "  実測ATE: 0.00568\n",
      "  推定ATE: 0.00478\n",
      "\n",
      "予測: s_learner\n",
      "  成功: 19200件の予測\n",
      "\n",
      "予測: t_learner\n",
      "  成功: 19200件の予測\n",
      "\n",
      "予測: x_learner\n",
      "  成功: 19200件の予測\n",
      "\n",
      "予測: r_learner\n",
      "  成功: 19200件の予測\n",
      "\n",
      "予測: causal_tree\n",
      "  成功: 38400件の予測\n",
      "  警告: 予測サイズ(38400)がテストデータサイズ(19200)と異なります\n",
      "  2倍のサイズのため1つおきに選択: 19200件\n",
      "\n",
      "予測: uplift_rf\n",
      "  成功: 19200件の予測\n",
      "\n",
      "アップリフト評価メトリクス:\n",
      "  s_learner:\n",
      "    Qini係数: 0.2604\n",
      "    AUUC: 0.0282\n",
      "    上位20%アップリフト: 0.0065\n",
      "    予測-実績相関: 0.5496\n",
      "  アップリフトカーブを 'uplift_curve_s_learner.png' として保存しました\n",
      "  t_learner:\n",
      "    Qini係数: 0.2810\n",
      "    AUUC: 0.0286\n",
      "    上位20%アップリフト: 0.0082\n",
      "    予測-実績相関: 0.6631\n",
      "  アップリフトカーブを 'uplift_curve_t_learner.png' として保存しました\n",
      "  x_learner:\n",
      "    Qini係数: 0.3009\n",
      "    AUUC: 0.0291\n",
      "    上位20%アップリフト: 0.0077\n",
      "    予測-実績相関: 0.4624\n",
      "  アップリフトカーブを 'uplift_curve_x_learner.png' として保存しました\n",
      "  r_learner:\n",
      "    Qini係数: 0.1630\n",
      "    AUUC: 0.0260\n",
      "    上位20%アップリフト: 0.0087\n",
      "    予測-実績相関: 0.5091\n",
      "  アップリフトカーブを 'uplift_curve_r_learner.png' として保存しました\n",
      "  causal_tree:\n",
      "    Qini係数: -0.4387\n",
      "    AUUC: 0.0077\n",
      "    上位20%アップリフト: -0.0041\n",
      "    予測-実績相関: -0.6184\n",
      "  アップリフトカーブを 'uplift_curve_causal_tree.png' として保存しました\n",
      "  uplift_rf:\n",
      "    Qini係数: 0.4419\n",
      "    AUUC: 0.0322\n",
      "    上位20%アップリフト: 0.0090\n",
      "    予測-実績相関: 0.7004\n",
      "  アップリフトカーブを 'uplift_curve_uplift_rf.png' として保存しました\n",
      "\n",
      "=== モデル性能比較 ===\n",
      "1位: uplift_rf (Qini係数: 0.4419)\n",
      "2位: x_learner (Qini係数: 0.3009)\n",
      "3位: t_learner (Qini係数: 0.2810)\n",
      "4位: s_learner (Qini係数: 0.2604)\n",
      "5位: r_learner (Qini係数: 0.1630)\n",
      "6位: causal_tree (Qini係数: -0.4387)\n",
      "\n",
      "最良モデル: uplift_rf (Qini係数: 0.4419)\n",
      "\n",
      "モデル比較チャートを 'uplift_model_comparison.png' として保存しました\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# APIエンドポイント\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# 評価関数を直接ファイル内に定義\n",
    "def calculate_uplift_metrics(y_true, treatment, uplift_scores, n_bins=10):\n",
    "    \"\"\"アップリフトモデルの評価メトリクスを計算する関数\"\"\"\n",
    "    # データフレーム作成\n",
    "    df = pd.DataFrame({\n",
    "        'y': y_true,\n",
    "        'w': treatment,\n",
    "        'uplift': uplift_scores\n",
    "    })\n",
    "    \n",
    "    # アップリフト値に基づいてn_bins個の等分位点で分割\n",
    "    df['bin'] = pd.qcut(df['uplift'], q=n_bins, labels=False, duplicates='drop')\n",
    "    \n",
    "    # ビン別の集計\n",
    "    bin_stats = []\n",
    "    total_treat = df[df['w'] == 1].shape[0]\n",
    "    total_control = df[df['w'] == 0].shape[0]\n",
    "    total_treat_converted = df[(df['w'] == 1) & (df['y'] == 1)].shape[0]\n",
    "    total_control_converted = df[(df['w'] == 0) & (df['y'] == 1)].shape[0]\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        bin_df = df[df['bin'] == i]\n",
    "        if len(bin_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 各ビンでの処置群と対照群のサイズとコンバージョン数\n",
    "        treat_size = bin_df[bin_df['w'] == 1].shape[0]\n",
    "        control_size = bin_df[bin_df['w'] == 0].shape[0]\n",
    "        \n",
    "        if treat_size == 0 or control_size == 0:\n",
    "            continue\n",
    "            \n",
    "        treat_conv = bin_df[(bin_df['w'] == 1) & (bin_df['y'] == 1)].shape[0]\n",
    "        control_conv = bin_df[(bin_df['w'] == 0) & (bin_df['y'] == 1)].shape[0]\n",
    "            \n",
    "        # コンバージョン率とアップリフト\n",
    "        treat_conv_rate = treat_conv / treat_size\n",
    "        control_conv_rate = control_conv / control_size\n",
    "        bin_uplift = treat_conv_rate - control_conv_rate\n",
    "        \n",
    "        bin_stats.append({\n",
    "            'bin': i,\n",
    "            'size': bin_df.shape[0],\n",
    "            'treat_size': treat_size,\n",
    "            'control_size': control_size,\n",
    "            'treat_conv': treat_conv,\n",
    "            'control_conv': control_conv,\n",
    "            'treat_conv_rate': treat_conv_rate,\n",
    "            'control_conv_rate': control_conv_rate,\n",
    "            'uplift': bin_uplift,\n",
    "            'mean_pred_uplift': bin_df['uplift'].mean()\n",
    "        })\n",
    "    \n",
    "    # 結果がない場合はデフォルト値を返す\n",
    "    if not bin_stats:\n",
    "        return {\n",
    "            'auuc': 0.0,\n",
    "            'qini': 0.0,\n",
    "            'uplift_at_top_k': 0.0,\n",
    "            'corr': 0.0\n",
    "        }\n",
    "    \n",
    "    bin_df = pd.DataFrame(bin_stats)\n",
    "    bin_df = bin_df.sort_values('mean_pred_uplift', ascending=False)\n",
    "    \n",
    "    # 各種メトリクスを計算\n",
    "    # AUUCとQini係数\n",
    "    total_pop = total_treat + total_control\n",
    "    cum_treat = 0\n",
    "    cum_control = 0\n",
    "    cum_treat_conv = 0\n",
    "    cum_control_conv = 0\n",
    "    \n",
    "    auuc_values = []\n",
    "    random_auuc_values = []\n",
    "    \n",
    "    for _, row in bin_df.iterrows():\n",
    "        cum_treat += row['treat_size']\n",
    "        cum_control += row['control_size']\n",
    "        cum_treat_conv += row['treat_conv']\n",
    "        cum_control_conv += row['control_conv']\n",
    "        \n",
    "        # 累積アップリフト\n",
    "        cum_treat_rate = cum_treat_conv / cum_treat if cum_treat > 0 else 0\n",
    "        cum_control_rate = cum_control_conv / cum_control if cum_control > 0 else 0\n",
    "        \n",
    "        # 全体のアップリフト\n",
    "        overall_treat_rate = total_treat_converted / total_treat if total_treat > 0 else 0\n",
    "        overall_control_rate = total_control_converted / total_control if total_control > 0 else 0\n",
    "        \n",
    "        auuc_values.append((cum_treat_rate - cum_control_rate) * (cum_treat + cum_control) / total_pop)\n",
    "        random_auuc_values.append((overall_treat_rate - overall_control_rate) * (cum_treat + cum_control) / total_pop)\n",
    "    \n",
    "    # AUUC\n",
    "    auuc = np.trapz(auuc_values) if auuc_values else 0\n",
    "    random_auuc = np.trapz(random_auuc_values) if random_auuc_values else 0\n",
    "    \n",
    "    # Qini\n",
    "    qini = (auuc - random_auuc) / (abs(random_auuc) + 1e-10) if random_auuc != 0 else 0\n",
    "    \n",
    "    # 上位20%でのアップリフト\n",
    "    top_20_pct = max(1, int(len(bin_df) * 0.2))\n",
    "    top_k_uplift = bin_df.iloc[:top_20_pct]['uplift'].mean() if len(bin_df) > 0 else 0\n",
    "    \n",
    "    # 相関\n",
    "    corr = bin_df['mean_pred_uplift'].corr(bin_df['uplift']) if len(bin_df) > 1 else 0\n",
    "    \n",
    "    return {\n",
    "        'auuc': float(auuc),\n",
    "        'qini': float(qini),\n",
    "        'uplift_at_top_k': float(top_k_uplift),\n",
    "        'corr': float(corr)\n",
    "    }\n",
    "\n",
    "def plot_uplift_curve(y_true, treatment, uplift_scores, title=\"Uplift Curve\", save_path=None):\n",
    "    \"\"\"アップリフトカーブをプロットする関数\"\"\"\n",
    "    # データフレーム作成\n",
    "    df = pd.DataFrame({\n",
    "        'y': y_true,\n",
    "        'w': treatment,\n",
    "        'uplift': uplift_scores\n",
    "    })\n",
    "    \n",
    "    # スコアで降順にソート\n",
    "    df = df.sort_values('uplift', ascending=False)\n",
    "    \n",
    "    # 人口割合ごとの累積アップリフト計算\n",
    "    n_bins = 10\n",
    "    population_fractions = np.linspace(0, 1, n_bins+1)[1:]\n",
    "    \n",
    "    incremental_uplifts = []\n",
    "    random_uplifts = []\n",
    "    \n",
    "    # 全体のアップリフト平均\n",
    "    total_treat_rate = df[df['w'] == 1]['y'].mean()\n",
    "    total_control_rate = df[df['w'] == 0]['y'].mean()\n",
    "    total_uplift = total_treat_rate - total_control_rate\n",
    "    \n",
    "    for fraction in population_fractions:\n",
    "        subset_size = int(len(df) * fraction)\n",
    "        subset = df.iloc[:subset_size]\n",
    "        \n",
    "        # 処置群と対照群のコンバージョン率\n",
    "        treat_rate = subset[subset['w'] == 1]['y'].mean() if subset[subset['w'] == 1].shape[0] > 0 else 0\n",
    "        control_rate = subset[subset['w'] == 0]['y'].mean() if subset[subset['w'] == 0].shape[0] > 0 else 0\n",
    "        \n",
    "        incremental_uplifts.append(treat_rate - control_rate)\n",
    "        random_uplifts.append(total_uplift * fraction)\n",
    "    \n",
    "    # プロット作成\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(population_fractions, incremental_uplifts, marker='o', label='Model Uplift')\n",
    "    ax.plot(population_fractions, random_uplifts, linestyle='--', label='Random Targeting')\n",
    "    ax.axhline(y=total_uplift, color='r', linestyle=':', label=f'Average Uplift ({total_uplift:.5f})')\n",
    "    \n",
    "    ax.set_xlabel('Population Fraction')\n",
    "    ax.set_ylabel('Uplift')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # メトリクスをテキストとして追加\n",
    "    metrics = calculate_uplift_metrics(y_true, treatment, uplift_scores)\n",
    "    metrics_text = f\"AUUC: {metrics['auuc']:.5f}\\nQini: {metrics['qini']:.5f}\\nTop 20% Uplift: {metrics['uplift_at_top_k']:.5f}\"\n",
    "    ax.text(0.02, 0.02, metrics_text, transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    # 1. データ読み込み\n",
    "    try:\n",
    "        df = pd.read_csv(\"hillstrom.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"hillstrom.csvが見つかりません。カレントディレクトリにファイルが存在するか確認してください。\")\n",
    "        return\n",
    "    \n",
    "    print(f\"データ件数: {len(df)}\")\n",
    "    \n",
    "    # 2. 前処理\n",
    "    df.columns = [col.capitalize() for col in df.columns]\n",
    "    df['treatment'] = (df['Segment'] != 'No E-Mail').astype(int)\n",
    "    \n",
    "    # 分析で使う特徴量\n",
    "    features = ['Recency', 'History', 'Mens', 'Womens', 'Newbie']\n",
    "    \n",
    "    # データ分割 (各モデル間で同じテストデータを使う)\n",
    "    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['treatment'])\n",
    "    print(f\"訓練データ: {len(train_df)}件, テストデータ: {len(test_df)}件\")\n",
    "    \n",
    "    # 3. トレーニング用データの準備とAPIリクエスト\n",
    "    train_data = train_df.to_dict('records')\n",
    "    \n",
    "    # 各モデルタイプをトレーニング\n",
    "    model_types = [\"s_learner\", \"t_learner\", \"x_learner\", \"r_learner\", \"causal_tree\", \"uplift_rf\"]\n",
    "    model_paths = {}\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        print(f\"\\nトレーニング: {model_type}\")\n",
    "        train_payload = {\n",
    "            \"data\": train_data,\n",
    "            \"features\": features,\n",
    "            \"treatment_col\": \"treatment\",\n",
    "            \"outcome_col\": \"Conversion\",\n",
    "            \"model_type\": model_type,\n",
    "            \"model_params\": {\n",
    "                \"n_estimators\": 100,\n",
    "                \"max_depth\": 5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(f\"{API_URL}/train\", json=train_payload)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            model_path = result[\"model_path\"]\n",
    "            model_paths[model_type] = model_path\n",
    "            metrics = result[\"model_info\"][\"metrics\"]\n",
    "            print(f\"  成功: {model_type}\")\n",
    "            print(f\"  実測ATE: {metrics.get('actual_ate'):.5f}\")\n",
    "            print(f\"  推定ATE: {metrics.get('estimated_ate'):.5f}\")\n",
    "        else:\n",
    "            print(f\"  失敗: {response.text}\")\n",
    "    \n",
    "    # 4. テスト用データの準備と予測\n",
    "    test_features = test_df[features].to_dict('records')\n",
    "    \n",
    "    # 5. 各モデルで予測を実行\n",
    "    predictions = {}\n",
    "    \n",
    "    for model_type, model_path in model_paths.items():\n",
    "        print(f\"\\n予測: {model_type}\")\n",
    "        predict_payload = {\n",
    "            \"features\": test_features,\n",
    "            \"model_path\": model_path\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(f\"{API_URL}/predict\", json=predict_payload)\n",
    "            response.raise_for_status()  # ステータスコードが4xx/5xxの場合は例外を発生\n",
    "            result = response.json()\n",
    "            preds = result[\"predictions\"]\n",
    "            print(f\"  成功: {len(preds)}件の予測\")\n",
    "            \n",
    "            # 予測結果のサイズ修正\n",
    "            if len(preds) != len(test_df):\n",
    "                print(f\"  警告: 予測サイズ({len(preds)})がテストデータサイズ({len(test_df)})と異なります\")\n",
    "                if len(preds) == 2 * len(test_df):\n",
    "                    # causal_treeは1件の予測に対して2つの値を返す場合がある\n",
    "                    preds = preds[::2]\n",
    "                    print(f\"  2倍のサイズのため1つおきに選択: {len(preds)}件\")\n",
    "                elif len(preds) > len(test_df):\n",
    "                    preds = preds[:len(test_df)]\n",
    "                    print(f\"  サイズが大きいため切り詰め: {len(preds)}件\")\n",
    "                else:\n",
    "                    mean_val = np.mean(preds)\n",
    "                    preds = preds + [mean_val] * (len(test_df) - len(preds))\n",
    "                    print(f\"  サイズが小さいため平均値で埋め: {len(preds)}件\")\n",
    "            \n",
    "            # R-learnerの異常値修正\n",
    "            if model_type == 'r_learner':\n",
    "                preds_array = np.array(preds, dtype=float)\n",
    "                outliers = np.abs(preds_array) > 1\n",
    "                if np.any(outliers):\n",
    "                    outlier_count = np.sum(outliers)\n",
    "                    print(f\"  警告: {outlier_count}件の異常値を検出\")\n",
    "                    median = np.median(preds_array[~outliers]) if np.sum(~outliers) > 0 else 0\n",
    "                    preds_array[outliers] = median\n",
    "                    print(f\"  異常値を中央値({median:.5f})で置換\")\n",
    "                    preds = preds_array.tolist()\n",
    "            \n",
    "            predictions[model_type] = preds\n",
    "        except Exception as e:\n",
    "            print(f\"  失敗: {str(e)}\")\n",
    "    \n",
    "    # 6. アップリフト評価\n",
    "    y_test = test_df['Conversion'].values\n",
    "    w_test = test_df['treatment'].values\n",
    "    \n",
    "    print(\"\\nアップリフト評価メトリクス:\")\n",
    "    all_scores = {}\n",
    "    \n",
    "    for model_type, preds in predictions.items():\n",
    "        try:\n",
    "            # NaN値のチェックと置換\n",
    "            preds_array = np.array(preds, dtype=float)\n",
    "            if np.isnan(preds_array).any():\n",
    "                print(f\"  {model_type}: NaN値があります。平均値で置換します。\")\n",
    "                mean_val = np.nanmean(preds_array)\n",
    "                preds_array = np.nan_to_num(preds_array, nan=mean_val)\n",
    "            \n",
    "            # メトリクスを計算\n",
    "            metrics = calculate_uplift_metrics(y_test, w_test, preds_array)\n",
    "            all_scores[model_type] = metrics['qini']\n",
    "            \n",
    "            print(f\"  {model_type}:\")\n",
    "            print(f\"    Qini係数: {metrics['qini']:.4f}\")\n",
    "            print(f\"    AUUC: {metrics['auuc']:.4f}\")\n",
    "            print(f\"    上位20%アップリフト: {metrics['uplift_at_top_k']:.4f}\")\n",
    "            print(f\"    予測-実績相関: {metrics['corr']:.4f}\")\n",
    "            \n",
    "            # アップリフトカーブをプロット\n",
    "            save_path = f\"uplift_curve_{model_type}.png\"\n",
    "            fig = plot_uplift_curve(\n",
    "                y_test, w_test, preds_array,\n",
    "                title=f\"Uplift Curve - {model_type}\",\n",
    "                save_path=save_path\n",
    "            )\n",
    "            print(f\"  アップリフトカーブを '{save_path}' として保存しました\")\n",
    "            plt.close(fig)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  {model_type}の評価エラー: {str(e)}\")\n",
    "    \n",
    "    # 7. モデル比較\n",
    "    if all_scores:\n",
    "        print(\"\\n=== モデル性能比較 ===\")\n",
    "        sorted_models = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        for i, (model, score) in enumerate(sorted_models):\n",
    "            print(f\"{i+1}位: {model} (Qini係数: {score:.4f})\")\n",
    "        \n",
    "        best_model = sorted_models[0][0]\n",
    "        print(f\"\\n最良モデル: {best_model} (Qini係数: {all_scores[best_model]:.4f})\")\n",
    "        \n",
    "        # 全モデルの比較プロット\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for model_type, preds in predictions.items():\n",
    "            # データ準備\n",
    "            df = pd.DataFrame({\n",
    "                'y': y_test,\n",
    "                'w': w_test,\n",
    "                'uplift': np.array(preds, dtype=float)\n",
    "            })\n",
    "            \n",
    "            # スコアで降順にソート\n",
    "            df = df.sort_values('uplift', ascending=False)\n",
    "            \n",
    "            # 人口割合ごとの累積アップリフト計算\n",
    "            population_fractions = np.linspace(0, 1, 21)[1:]  # 5%ごと\n",
    "            incremental_uplifts = []\n",
    "            \n",
    "            for fraction in population_fractions:\n",
    "                subset_size = int(len(df) * fraction)\n",
    "                subset = df.iloc[:subset_size]\n",
    "                \n",
    "                treat_size = subset[subset['w'] == 1].shape[0]\n",
    "                control_size = subset[subset['w'] == 0].shape[0]\n",
    "                \n",
    "                if treat_size > 0 and control_size > 0:\n",
    "                    treat_rate = subset[subset['w'] == 1]['y'].mean()\n",
    "                    control_rate = subset[subset['w'] == 0]['y'].mean()\n",
    "                    incremental_uplifts.append(treat_rate - control_rate)\n",
    "                else:\n",
    "                    # 処置群または対照群がない場合は直前の値を使用するか0\n",
    "                    incremental_uplifts.append(incremental_uplifts[-1] if incremental_uplifts else 0)\n",
    "            \n",
    "            # プロット\n",
    "            plt.plot(population_fractions, incremental_uplifts, marker='o', \n",
    "                     label=f\"{model_type} (Qini={all_scores[model_type]:.4f})\")\n",
    "        \n",
    "        # ランダムターゲティング線\n",
    "        total_treat_rate = df[df['w'] == 1]['y'].mean()\n",
    "        total_control_rate = df[df['w'] == 0]['y'].mean()\n",
    "        total_uplift = total_treat_rate - total_control_rate\n",
    "        \n",
    "        plt.plot(population_fractions, [total_uplift * f for f in population_fractions], \n",
    "                 linestyle='--', label='Random Targeting')\n",
    "        plt.axhline(y=total_uplift, color='r', linestyle=':', \n",
    "                   label=f'Average Uplift ({total_uplift:.5f})')\n",
    "        \n",
    "        plt.xlabel('Population Fraction')\n",
    "        plt.ylabel('Uplift')\n",
    "        plt.title('Uplift Curves - Model Comparison')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        model_comparison_path = \"uplift_model_comparison.png\"\n",
    "        plt.savefig(model_comparison_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\nモデル比較チャートを '{model_comparison_path}' として保存しました\")\n",
    "        plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"エラーが発生しました: {str(e)}\")\n",
    "        print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b6891-47f8-4ea8-9a8d-6ce73032c68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0c28d-1597-411e-b9b5-4377d5cfc41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c04d1f-bd94-48c1-adbd-dcef463c70ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a37248-ea71-47c2-992e-82bcf0087294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8241c1-e775-4177-bb69-cabbc9c4f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ件数: 64000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>history_segment</th>\n",
       "      <th>history</th>\n",
       "      <th>mens</th>\n",
       "      <th>womens</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>newbie</th>\n",
       "      <th>channel</th>\n",
       "      <th>segment</th>\n",
       "      <th>visit</th>\n",
       "      <th>conversion</th>\n",
       "      <th>spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2) $100 - $200</td>\n",
       "      <td>142.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Womens E-Mail</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3) $200 - $350</td>\n",
       "      <td>329.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>No E-Mail</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2) $100 - $200</td>\n",
       "      <td>180.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Surburban</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>Womens E-Mail</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>5) $500 - $750</td>\n",
       "      <td>675.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mens E-Mail</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1) $0 - $100</td>\n",
       "      <td>45.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>0</td>\n",
       "      <td>Web</td>\n",
       "      <td>Womens E-Mail</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recency history_segment  history  mens  womens   zip_code  newbie channel  \\\n",
       "0       10  2) $100 - $200   142.44     1       0  Surburban       0   Phone   \n",
       "1        6  3) $200 - $350   329.08     1       1      Rural       1     Web   \n",
       "2        7  2) $100 - $200   180.65     0       1  Surburban       1     Web   \n",
       "3        9  5) $500 - $750   675.83     1       0      Rural       1     Web   \n",
       "4        2    1) $0 - $100    45.34     1       0      Urban       0     Web   \n",
       "\n",
       "         segment  visit  conversion  spend  \n",
       "0  Womens E-Mail      0           0    0.0  \n",
       "1      No E-Mail      0           0    0.0  \n",
       "2  Womens E-Mail      0           0    0.0  \n",
       "3    Mens E-Mail      0           0    0.0  \n",
       "4  Womens E-Mail      0           0    0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../../hillstrom.csv\")\n",
    "print(\"データ件数:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d76348-16a0-4f6f-87ac-25531312c3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency</th>\n",
       "      <th>History</th>\n",
       "      <th>Mens</th>\n",
       "      <th>Womens</th>\n",
       "      <th>Newbie</th>\n",
       "      <th>treatment</th>\n",
       "      <th>Conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency  History  Mens  Womens  Newbie  treatment  Conversion\n",
       "0       10      100     1       0       0          1           1\n",
       "1        5      200     0       1       0          0           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_payload[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a690f36-a34e-4d65-8a77-f519b82acc06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
